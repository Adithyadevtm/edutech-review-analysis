# -*- coding: utf-8 -*-
"""main_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rj0YnXAqRZaPSsz1xen7tC-KHk_QLL50
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

file_path = '/content/drive/My Drive/main_project.csv'

# Try reading the file using a different encoding
df = pd.read_csv(file_path, encoding='ISO-8859-1')  # or try 'latin1' if this fails
df.head()

df.info()
df.describe(include='all')
df['Rating_sentiment'].value_counts()

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=df, x='Rating', hue='Rating_sentiment')
plt.title("Ratings vs Sentiment")
plt.show()

from wordcloud import WordCloud

text = ' '.join(df[df['Rating_sentiment'] == 'Negative']['Review_text'].dropna())
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Negative Review WordCloud")
plt.show()

# Check for missing values
df.isnull().sum()

# Drop or fill nulls if necessary
# df.dropna(inplace=True)
# or
# df['column_name'].fillna('Unknown', inplace=True)

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=df, x='Rating_sentiment')
plt.title('Sentiment Distribution')
plt.show()

from wordcloud import WordCloud

text = ' '.join(df['Review_text'].dropna().astype(str))
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Most Frequent Words in Reviews')
plt.show()

df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date')['Rating'].resample('W').count().plot()
plt.title('Number of Reviews Over Time')
plt.xlabel('Date')
plt.ylabel('Review Count')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Keep only Positive and Negative sentiments
df = df[df['Rating_sentiment'].isin(['Positive', 'Negative'])]

# Inputs and labels
X = df['Review_text']
y = df['Rating_sentiment']

# Vectorize text
vectorizer = TfidfVectorizer(stop_words='english')
X_vectorized = vectorizer.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)

# Train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

print("Training Set:\n", y_train.value_counts())
print("\nTest Set:\n", y_test.value_counts())

from imblearn.over_sampling import SMOTE

# Create SMOTE object
smote = SMOTE(random_state=42)

# Resample training data only
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Check new class distribution
print("Resampled Training Set:\n", y_train_resampled.value_counts())

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Train again
model = LogisticRegression()
model.fit(X_train_resampled, y_train_resampled)

# Predict and evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Try Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_resampled, y_train_resampled)
y_pred_rf = rf_model.predict(X_test)
print("Random Forest:\n", classification_report(y_test, y_pred_rf))

# Try SVM
svm_model = SVC()
svm_model.fit(X_train_resampled, y_train_resampled)
y_pred_svm = svm_model.predict(X_test)
print("SVM:\n", classification_report(y_test, y_pred_svm))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred, labels=['Negative', 'Positive'])
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])
disp.plot(cmap='Blues')

y_prob = model.predict_proba(X_test)[:, 1]
y_pred_thresh = ['Positive' if prob > 0.3 else 'Negative' for prob in y_prob]
print(classification_report(y_test, y_pred_thresh))

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_resampled, y_train_resampled)

y_pred_rf = rf_model.predict(X_test)
print(classification_report(y_test, y_pred_rf))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm_rf = confusion_matrix(y_test, y_pred_rf, labels=['Negative', 'Positive'])
disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=['Negative', 'Positive'])
disp_rf.plot(cmap='Blues')

import joblib

# Save the model
joblib.dump(rf_model, 'random_forest_model.pkl')

# Later you can load it like this:
# loaded_model = joblib.load('random_forest_model.pkl')

# Example: if you used TfidfVectorizer to train
new_review = ["This edutech company is amazing! Loved it."]

# Transform using the same vectorizer used for training
new_review_vectorized = vectorizer.transform(new_review)

# Predict using the trained model
prediction = rf_model.predict(new_review_vectorized)

print("Predicted label:", prediction[0])

def predict_review(review_text):
    vectorized = vectorizer.transform([review_text])
    result = rf_model.predict(vectorized)
    return result[0]

# Try it out
predict_review("The service was terrible, very bad experience.")

reviews = [
    "This platform helped me a lot, very useful.",
    "Worst experience ever. Totally waste of time.",
    "Customer support was friendly and quick.",
    "I didn’t like the service at all.",
    "Great content, very informative."
]

# Transform all reviews at once
review_vectors = vectorizer.transform(reviews)

# Predict using your model
predictions = rf_model.predict(review_vectors)

# Print results
for review, prediction in zip(reviews, predictions):
    print(f"Review: {review} → Prediction: {prediction}")